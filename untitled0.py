# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AGFkmVx9YEoauTEGieNTxbGRY10i6_5A
"""

import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Path to the CSV file in Drive
df = pd.read_csv('/content/drive/My Drive/data.csv')

# Display the first few rows
print(df.head())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Now, let's extract the relevant columns from the DataFrame to create our feature matrix X and target variable y.
# 'X' will contain the independent variables (bedrooms, bathrooms, sqft_living, sqft_lot, floors, waterfront, view, condition)
# 'y' will contain the target variable (price)

X = df[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition']]
y = df['price']

# Next, you can split the dataset into training and testing sets using sklearn's train_test_split function:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Now, let's specify the feature names for X to avoid the warning message:
feature_names = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition']
X_train.columns = feature_names
X_test.columns = feature_names

# Now, you can build your linear regression model using sklearn's LinearRegression class:
model = LinearRegression()

# Fit the model on the training data
model.fit(X_train, y_train)

# Once the model is trained, you can use it to make predictions on new data (test set in this case):
y_pred = model.predict(X_test)

# To evaluate the model's performance, you can use metrics such as Mean Squared Error (MSE) and R-squared:
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared:", r2)
# Assuming your dataset is in a CSV file named 'data.csv', you can read it into a pandas DataFrame as follows:
df = pd.read_csv('data.csv')

# Let's take a look at the first few rows of the dataset to understand its structure
print(df.head())
# You can also use the trained model to make predictions on new data by providing the feature values:
# For example, to predict the price of a house with 3 bedrooms, 2 bathrooms, 1500 sqft living area, 4000 sqft lot, 1 floor, not waterfront, no view, and condition 3:
new_data = [[3, 2, 1500, 4000, 1, 0, 0, 3]]
predicted_price = model.predict(new_data)
print("Predicted Price:", predicted_price[0])

plt.figure(figsize=(8, 6))  # Adjust figure size if needed
plt.scatter(y_test, y_pred, alpha=0.5)  # Alpha controls point transparency
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs. Predicted House Prices")
plt.grid(True)  # Add a grid for better readability
plt.show()

sns.set_style("whitegrid")  # Choose a style like 'darkgrid', 'whitegrid', 'ticks', etc.

plt.figure(figsize=(10, 8))  # Adjust figure size for better proportions
sns.regplot(x=y_test, y=y_pred, scatter_kws={'alpha':0.6, 'color':'blue'}, line_kws={'color':'red'})
plt.xlabel("Actual Prices", fontsize=14)
plt.ylabel("Predicted Prices", fontsize=14)
plt.title("Actual vs. Predicted House Prices", fontsize=16)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)  # Customize grid style
plt.show()

